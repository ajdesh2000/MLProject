{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from statistics import median, mean\n",
    "from collections import Counter\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import Add\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CartPoleEnv - Version 0.2.0, Noise case: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanish3/anaconda3/envs/mlproject/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/mohanish3/anaconda3/envs/mlproject/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'gym.envs.classic_control.cartpole.CartPoleEnv'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-3\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot score over episodes\n",
    "def plot_res(values, title=''):   \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Define the figure\n",
    "    f, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n",
    "    f.suptitle(title)\n",
    "    ax[0].plot(values, label='score per run')\n",
    "    ax[0].axhline(500, c='red',ls='--', label='goal')\n",
    "    ax[0].set_xlabel('Episodes')\n",
    "    ax[0].set_ylabel('Reward')\n",
    "    x = range(len(values))\n",
    "    ax[0].legend()\n",
    "    # Calculate the trend\n",
    "    try:\n",
    "        z = np.polyfit(x, values, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax[0].plot(x,p(x),\"--\", label='trend')\n",
    "    except:\n",
    "        print('')\n",
    "    \n",
    "    # Plot the histogram of results\n",
    "    ax[1].hist(values[-50:])\n",
    "    ax[1].axvline(500, c='red', label='goal')\n",
    "    ax[1].set_xlabel('Scores per Last 50 Episodes')\n",
    "    ax[1].set_ylabel('Frequency')\n",
    "    ax[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = env.observation_space.shape\n",
    "output_size = env.action_space.n\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "actor_critic_grads = tf.placeholder(tf.float32, [None, output_size])\n",
    "def actor_model(input_size, output_size):\n",
    "    global LEARNING_RATE\n",
    "\n",
    "    input_state = Input(shape=input_size)\n",
    "    output=Dense(24, activation='relu')(input_state)\n",
    "    #output=Dense(48, activation='relu')(output)\n",
    "    output=Dense(24, activation='relu')(output)\n",
    "    output=Dense(output_size, activation='softmax')(output)\n",
    "\n",
    "    \n",
    "    model = Model(input=input_state, output=output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=LEARNING_RATE), metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return input_state, model\n",
    "\n",
    "def critic_model(input_size_state, input_size_action):\n",
    "    LEARNING_RATE\n",
    "    \n",
    "    input_state = Input(shape=input_size_state)\n",
    "    state_hidden = Dense(24, activation='relu')(input_state)\n",
    "    state_hidden = Dense(24)(state_hidden)\n",
    "    \n",
    "    input_action = Input(shape=(input_size_action,))\n",
    "    action_hidden = Dense(24)(input_action)\n",
    "    action_hidden = Dense(24)(action_hidden)\n",
    "    \n",
    "    output = Add()([state_hidden, action_hidden])\n",
    "    output = Dense(24, activation='relu')(output)\n",
    "    output = Dense(1, activation='linear')(output)\n",
    "    \n",
    "    model = Model(input=[input_state,input_action], output=output)\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=Adam(lr=LEARNING_RATE), metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return input_state, input_action, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mohanish3/anaconda3/envs/mlproject/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanish3/.local/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 24)           120         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 24)           72          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 24)           600         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 24)           600         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 24)           0           dense_8[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 24)           600         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            25          dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,017\n",
      "Trainable params: 2,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 24)           120         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 24)           72          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 24)           600         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 24)           600         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24)           0           dense_14[0][0]                   \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 24)           600         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            25          dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,017\n",
      "Trainable params: 2,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanish3/.local/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "#Initializiing models with target models(For slow update in DDQL)\n",
    "actor_input_state,a_model = actor_model(input_size, output_size)\n",
    "_,a_target_model = actor_model(input_size, output_size)\n",
    "critic_input_state, critic_input_action, c_model = critic_model(input_size, output_size)\n",
    "_, _, c_target_model = critic_model(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_model_weights = a_model.trainable_weights\n",
    "actor_grads = tf.gradients(a_model.output, actor_model_weights, -actor_critic_grads)\n",
    "grads = zip(actor_grads, actor_model_weights)\n",
    "optimize = tf.train.AdamOptimizer(LEARNING_RATE).apply_gradients(grads)\n",
    "\n",
    "critic_grads = tf.gradients(c_model.output, critic_input_action)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay_actor(training_samples):\n",
    "    global sess, critic_grads, critic_input_state, critic_input_action, actor_critic_grads, optimize\n",
    "    \n",
    "    states = []\n",
    "    actions = []\n",
    "    for t in training_samples:\n",
    "        state, reward, done, new_state, action = t\n",
    "        \n",
    "        act = a_model.predict(np.expand_dims(state, axis=0))[0]\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(act)\n",
    "        \n",
    "    states = np.array(states)\n",
    "    actions = np.array(actions)\n",
    "        \n",
    "    grads = sess.run(critic_grads, feed_dict={\n",
    "        critic_input_state:  states, \n",
    "        critic_input_action: actions\n",
    "    })[0]\n",
    "\n",
    "    sess.run(optimize, feed_dict={\n",
    "        actor_input_state: states,\n",
    "        actor_critic_grads: grads\n",
    "    })\n",
    "        \n",
    "def replay_critic(training_samples):\n",
    "    global epsilon, epsilon_min, epsilon_decay, a_model, c_model, double\n",
    "    \n",
    "    states=[]\n",
    "    actions = []\n",
    "    y=[]\n",
    "    for t in training_samples:\n",
    "        state, reward, done, new_state, action = t\n",
    "        \n",
    "        new_state = np.expand_dims(new_state, axis=0)\n",
    "        \n",
    "        if(done):\n",
    "            reward=-reward\n",
    "        else:\n",
    "            if not double:\n",
    "                #Deep q learning\n",
    "                a = a_model.predict(new_state)\n",
    "                t = c_model.predict([new_state, a])[0][0]\n",
    "            else:\n",
    "                #Double deep q learning\n",
    "                a = a_target_model.predict(new_state)\n",
    "                t = c_target_model.predict([new_state, a])[0][0]\n",
    "            reward = reward + gamma * t\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        y.append(reward)\n",
    "            \n",
    "    states = np.array(states)\n",
    "    actions = np.array(actions)\n",
    "        \n",
    "    y = np.expand_dims(np.array(y), axis=1)\n",
    "    #print(y.shape)\n",
    "        \n",
    "    c_model.fit([states, actions], y, batch_size=len(training_samples), verbose=0)\n",
    "    \n",
    "def replay(training_data, train_size):\n",
    "    global epsilon, epsilon_min, epsilon_decay, a_model, c_model\n",
    "    \n",
    "    if(len(training_data) < train_size):\n",
    "        return\n",
    "    \n",
    "    batch_data = random.sample(training_data, train_size)\n",
    "    \n",
    "    replay_critic(batch_data)\n",
    "    replay_actor(batch_data)\n",
    "    \n",
    "    epsilon = max(epsilon*epsilon_decay, epsilon_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_actor_target():\n",
    "    global a_model, a_target_model\n",
    "    a_target_model.set_weights(a_model.get_weights())\n",
    "    \n",
    "def update_critic_target():\n",
    "    global c_model, c_target_model\n",
    "    c_target_model.set_weights(c_model.get_weights())\n",
    "    \n",
    "def update_targets():\n",
    "    update_actor_target()\n",
    "    update_critic_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_action(state, output_size):\n",
    "    global epsilon, a_model\n",
    "    if(np.random.rand() <= epsilon): #Explore: Random action\n",
    "        act = [0] * output_size\n",
    "        act[np.random.randint(0, output_size)] = 1\n",
    "        act = np.array(act, dtype=np.float32)\n",
    "        return act\n",
    "    return a_model.predict(np.expand_dims(state, axis=0))[0] #Exploitation: Action with best possible reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 100 score : 500.0, epsilon=0.01\n",
      "Game 200 score : 11.0, epsilon=0.01\n",
      "Game 300 score : 9.0, epsilon=0.01\n",
      "Game 400 score : 10.0, epsilon=0.01\n",
      "Game 500 score : 8.0, epsilon=0.01\n",
      "Game 600 score : 10.0, epsilon=0.01\n",
      "Game 700 score : 9.0, epsilon=0.01\n",
      "Game 800 score : 12.0, epsilon=0.01\n",
      "Game 900 score : 8.0, epsilon=0.01\n",
      "Game 1000 score : 156.0, epsilon=0.01\n",
      "Game 1100 score : 8.0, epsilon=0.01\n",
      "Game 1200 score : 9.0, epsilon=0.01\n",
      "Game 1300 score : 8.0, epsilon=0.01\n",
      "Game 1400 score : 10.0, epsilon=0.01\n",
      "Game 1500 score : 11.0, epsilon=0.01\n",
      "Game 1600 score : 10.0, epsilon=0.01\n",
      "Game 1700 score : 10.0, epsilon=0.01\n",
      "Game 1800 score : 10.0, epsilon=0.01\n",
      "Game 1900 score : 11.0, epsilon=0.01\n",
      "Game 2000 score : 11.0, epsilon=0.01\n",
      "Game 2100 score : 9.0, epsilon=0.01\n",
      "Game 2200 score : 9.0, epsilon=0.01\n",
      "Game 2300 score : 10.0, epsilon=0.01\n",
      "Game 2400 score : 8.0, epsilon=0.01\n",
      "Game 2500 score : 10.0, epsilon=0.01\n",
      "Game 2600 score : 11.0, epsilon=0.01\n",
      "Game 2700 score : 10.0, epsilon=0.01\n",
      "Game 2800 score : 9.0, epsilon=0.01\n",
      "Game 2900 score : 9.0, epsilon=0.01\n",
      "Game 3000 score : 8.0, epsilon=0.01\n",
      "Game 3100 score : 8.0, epsilon=0.01\n",
      "Game 3200 score : 9.0, epsilon=0.01\n",
      "Game 3300 score : 8.0, epsilon=0.01\n",
      "Game 3400 score : 8.0, epsilon=0.01\n",
      "Game 3500 score : 11.0, epsilon=0.01\n",
      "Game 3600 score : 9.0, epsilon=0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f68324144073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-778519614faa>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(training_data, train_size)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mreplay_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mreplay_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepsilon_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-778519614faa>\u001b[0m in \u001b[0;36mreplay_actor\u001b[0;34m(training_samples)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlproject/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/mlproject/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlproject/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3530\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3532\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3533\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3534\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlproject/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    494\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlproject/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    902\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlproject/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       \u001b[0munwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0munwrapped\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlproject/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36munwrapped\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_WeakObjectIdentityWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0munwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "game_memory = deque(maxlen=100000)\n",
    "SCORE_REQUIRED = 500\n",
    "N=100\n",
    "last_N_scores = deque(maxlen=N)\n",
    "\n",
    "SEED=42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "\n",
    "train_size = 32\n",
    "update_every = 1\n",
    "goal_steps = 500\n",
    "TRAIN_EPISODES = 10000\n",
    "\n",
    "epsilon = 1.0 #Defines the exploration range\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.99\n",
    "gamma = 0.99\n",
    "\n",
    "double = False #Double deep q\n",
    "relearn = True\n",
    "\n",
    "if(relearn):\n",
    "    epsilon = 0.01\n",
    "    a_model.load_weights('task1_a_model.h5') #Loading weights for continued learning\n",
    "    c_model.load_weights('task1_c_model.h5')\n",
    "\n",
    "for game in range(TRAIN_EPISODES):\n",
    "    state = env.reset()\n",
    "    \n",
    "    #env.render()\n",
    "    score = 0\n",
    "    for _ in range(goal_steps):\n",
    "        #print(state.shape)\n",
    "        #state = np.expand_dims(state, axis=0)\n",
    "        \n",
    "        action = next_action(state, output_size)\n",
    "        \n",
    "        #print(np.expand_dims(new_state, axis=1))\n",
    "        #print(action)\n",
    "                \n",
    "        new_state, reward, done, info = env.step(np.argmax(action))\n",
    "        \n",
    "        score += reward\n",
    "        \n",
    "        \n",
    "        game_memory.append((state, reward, done, new_state, action))\n",
    "        \n",
    "        state = new_state\n",
    "        if done: \n",
    "            #print(\"episode: {}/{}, score: {}, e: {:.2}\".format(game, TRAIN_EPISODES, _, epsilon))\n",
    "            break\n",
    "    \n",
    "    if(len(game_memory) < 1000):\n",
    "        continue\n",
    "    \n",
    "    replay(game_memory, train_size)\n",
    "    \n",
    "    if(double):\n",
    "        if game % update_every == 0: #For double deep q learning\n",
    "            update_targets()\n",
    "    \n",
    "    if(game % 100 == 0):\n",
    "        print('Game {} score : {}, epsilon={:.2}'.format(game, score, epsilon))\n",
    "        scores.append(score)\n",
    "        \n",
    "    #complete training if last 100 episodes yield more than required score\n",
    "    last_N_scores.append(score)\n",
    "    if(sum(last_N_scores)/N >= SCORE_REQUIRED):\n",
    "        print('Score {} achieved at {} game'.format(SCORE_REQUIRED, game))\n",
    "        break\n",
    "\n",
    "if(len(scores) > 0):\n",
    "    print('Average Score taken every 100 steps:',sum(scores)/len(scores))\n",
    "else:\n",
    "    print('Average Score:', SCORE_REQUIRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model.save_weights('task1_a_model.h5')\n",
    "c_model.save_weights('task1_c_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_res(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, a_model = actor_model(env.observation_space.shape, env.action_space.n)\n",
    "a_model.load_weights('task1_a_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EPISODES = 100\n",
    "goal_steps = 500\n",
    "epsilon = 0.01\n",
    "output_size = env.action_space.n\n",
    "\n",
    "scores = []\n",
    "for episode in range(TEST_EPISODES):\n",
    "    state = env.reset()\n",
    "    \n",
    "    score = 0\n",
    "    for _ in range(goal_steps):\n",
    "        env.render()\n",
    "        \n",
    "        action = next_action(state, output_size)\n",
    "        \n",
    "        new_state, reward, done, info = env.step(np.argmax(action))\n",
    "        score += reward\n",
    "        \n",
    "        state = new_state\n",
    "        if(done):\n",
    "            break\n",
    "            \n",
    "    scores.append(score)\n",
    "        \n",
    "plot_res(scores)        \n",
    "print(\"Average score over {} episodes: {}\".format(TEST_EPISODES, sum(scores)/len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python mlproject",
   "language": "python",
   "name": "mlproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
